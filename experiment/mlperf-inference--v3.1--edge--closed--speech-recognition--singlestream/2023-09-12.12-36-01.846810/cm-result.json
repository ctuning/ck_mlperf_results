[
  {
    "Accuracy": 92.56353018106384,
    "Accuracy_div_100": 0.92564,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/IEI/results/NF5468M6_A40x1_TRT/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "IEI",
    "Platform": "NF5468M6_A40x1_TRT",
    "Result": 28.565963,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NF5468M6 (1x A40, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "b86e60efaf0b4923",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/IEI/results/NF5468M6_A40x1_TRT/rnnt/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55902049651627,
    "Accuracy_div_100": 0.92559,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ConnectTechInc/results/Orin_NX_TRT/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "ConnectTechInc",
    "Platform": "Orin_NX_TRT",
    "Result": 203.023899,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Orin NX 16G (TensorRT) + CTI Hadron Carrier (NGX012)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "CTI Hadron Carrier for Orin-NX/Orin-NANO (NGX012) is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "CTI Jetson BSP ORIN-NX-NANO-35.3.1-V002-MLPERF (Jetson r35.3.1 L4T)",
    "uid": "c4f098d67fa548df",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ConnectTechInc/results/Orin_NX_TRT/rnnt/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT",
    "Result": 94.006947,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "db6cc89ca0744579",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_TRT/rnnt/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_NX_TRT/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT",
    "Result": 200.982465,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Orin NX 16G (TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "76ee6abe8b5a4a49",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT/rnnt/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.53421723150466,
    "Accuracy_div_100": 0.92534,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/rigel-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "rigel-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 33.828062,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "One Stop Systems Rigel Edge Supercomputer",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA HGX A100 SXM",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7502 32-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-78-generic-glibc2.35)",
    "uid": "f0253275a89349e9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/rigel-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-cpu-pytorch-v1.13.1-default_config/rnnt/singlestream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-cpu-pytorch-v1.13.1-default_config",
    "Result": 402.949448,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Pytorch v1.13.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "eb8a475da90e4b70",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-cpu-pytorch-v1.13.1-default_config/rnnt/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56353018106384,
    "Accuracy_div_100": 0.92564,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR7620_L4x1_TRT/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR7620_L4x1_TRT",
    "Result": 18.827436,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XR7620 (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "91c165fd4b084190",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR7620_L4x1_TRT/rnnt/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_L4x1_TRT/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR4520c_L4x1_TRT",
    "Result": 18.949137,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XR4520c (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "44a6ea6075384331",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR4520c_L4x1_TRT/rnnt/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40x4_edge_TRT/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R760xa_L40x4_edge_TRT",
    "Result": 14.258412,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge R760xa (4x L40, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "8ce1c21afbce4a06",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_L40x4_edge_TRT/rnnt/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.540981758326,
    "Accuracy_div_100": 0.92541,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nutanix",
    "Platform": "NX_3155G_G8_A100_PCIe_80GBx2_TRT",
    "Result": 32.468574,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NX_3155G_G8_A100_PCIe_80GBx2",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354 CPU @ 3.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "a8c85f3959914605",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/rnnt/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_L40x1_TRT/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5300G6_L40x1_TRT",
    "Result": 13.960885,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "H3C UniServer R5300 G6 (1x L40, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "db63698f12d645ca",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/H3C/results/R5300G6_L40x1_TRT/rnnt/SingleStream",
    "version": "v3.1"
  }
]
