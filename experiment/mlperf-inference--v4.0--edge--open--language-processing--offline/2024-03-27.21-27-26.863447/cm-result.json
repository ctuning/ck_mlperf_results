[
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 24.8239,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "43d1b05f51284646",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.88571389692375,
    "Accuracy_div_100": 0.87886,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 57.2763,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "da21b1fb8e6d4057",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.51275,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "765f567201894a2c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.29174382621062,
    "Accuracy_div_100": 0.90292,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 11.2458,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "c6421b2245d64714",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 55.8759,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "84c98e50d29a46aa",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.36718210138123,
    "Accuracy_div_100": 0.90367,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 87.0337,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "31b44464d80e4fca",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.81268530031994,
    "Accuracy_div_100": 0.90813,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 41.0727,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "235aa2dddcaa4b2f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 29.9816,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "93aba6ae6376467d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 24.5669,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "4b52019d66664a2a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.51694,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "9454978cc9ee420e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 11.5058,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "b89e0a49dffa4008",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.01097011863615,
    "Accuracy_div_100": 0.90011,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 20.9442,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "747cb3c99b3d4bb5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.9379,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "2c1179df2b284d20",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.14276789144404,
    "Accuracy_div_100": 0.90143,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 17.6165,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "TRIGKEY Mini PC Ryzen 5 5560",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5560U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.10 (linux-6.5.0-17-generic-glibc2.38)",
    "uid": "98492485bbc64288",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/AMD_Mini_PC-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 27.004,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "2fbb6d81090a4ffa",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.89212297504716,
    "Accuracy_div_100": 0.87892,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 44.7662,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "58ce4ff2df7c43c2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 64.134,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "d5a63718f20b46ba",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.40462194474198,
    "Accuracy_div_100": 0.90405,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 90.0017,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "b092303d69cb40bb",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.7887526723603,
    "Accuracy_div_100": 0.90789,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 33.1638,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "889e43376ec74c1c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 32.9594,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "836287d5fd014e0e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 26.7835,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "cf3e8b0acbbc4034",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 13.0995,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "4b1297b1e65b42fa",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.89212297504716,
    "Accuracy_div_100": 0.87892,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 23.1141,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "f3ecfe41f82d4944",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 32.9884,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "64b88f08e2484414",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.40462194474198,
    "Accuracy_div_100": 0.90405,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 47.1924,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "b0a1443936504acd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.7887526723603,
    "Accuracy_div_100": 0.90789,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 17.0601,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "6fe98dc4d1d44aef",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 16.9837,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "1701b7e56f7b4b35",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.9574,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "bd3e142550e74457",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/aws_c5.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 18.2922,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "b949f0f05bbb427d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.88571389692375,
    "Accuracy_div_100": 0.87886,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 34.9947,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "3313a8bbf7ce4da4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.1002,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "45abafabf3d44a8c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.29174382621062,
    "Accuracy_div_100": 0.90292,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 7.10203,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "3d99ab66285141f8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 41.3109,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "0f82cca9a8dd4e40",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.36718210138123,
    "Accuracy_div_100": 0.90367,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 55.2553,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "8c48f149035d436c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.81268530031994,
    "Accuracy_div_100": 0.90813,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 25.5183,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "6ff9fec3a9034b22",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 25.0774,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "c45a56fd5469440b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 18.0132,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "4a4755369bfe479b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.09354,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "fb04ce5f80c1414b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 8.9269,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "22c5da27eb8c401c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.01097011863615,
    "Accuracy_div_100": 0.90011,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.9917,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "aae3d8819bf04291",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.82064,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "3702ef4f49174cfc",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.14276789144404,
    "Accuracy_div_100": 0.90143,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.4613,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2023 (linux-6.1.77-99.164.amzn2023.x86_64-glibc2.34)",
    "uid": "3754d7c4abf8494e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.66538,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "f0b59d94d5c84369",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.88571389692375,
    "Accuracy_div_100": 0.87886,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 19.0903,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "244095f5834343ca",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 24.6438,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "80aba5d222a5474b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.36718210138123,
    "Accuracy_div_100": 0.90367,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 31.2663,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "107da9dbf39d4277",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.81268530031994,
    "Accuracy_div_100": 0.90813,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 14.2526,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "f14c91f9de1d4b7d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 14.0041,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "99e83277fa644bb7",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.50949,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance c5a.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7R32",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "3596d971647645d8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/c5a.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.9043,
    "Accuracy_div_100": 0.42904,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-intel-cpu-pytorch-vdefault-default_config/gptj-99/offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-intel-cpu-pytorch-vdefault-default_config",
    "Result": 0.326534,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge,datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Intel inference implementation with CM API, Pytorch git@927dc662386af052018212c7d01309a506fc94cd",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "66cf20e9d4c04c8d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-intel-cpu-pytorch-vdefault-default_config/gptj-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 105.09,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "322d490e9b79491a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.89212297504716,
    "Accuracy_div_100": 0.87892,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 204.347,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "b2ad5f65da25477c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 14.1282,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "54ba9da1c9b94198",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.26941848776319,
    "Accuracy_div_100": 0.90269,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 69.1786,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "f7b4489ca09941a9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 160.822,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "a9d738eceef343d2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.40462194474198,
    "Accuracy_div_100": 0.90405,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 268.655,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "a11afa06051f418e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.79584822581347,
    "Accuracy_div_100": 0.90796,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 67.6974,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "f91c30da6ccc418f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 61.2531,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "66ad2a7148104c5e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 106.096,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "a045d1e9bbcd4d80",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 14.2471,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "e7740ea04e3c494a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 48.3105,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "9365061424484571",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.0299132434367,
    "Accuracy_div_100": 0.9003,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 90.1756,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "78473b7fd7a94079",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 53.4944,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "d6a58e1d7ade4d43",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1810702860831,
    "Accuracy_div_100": 0.90181,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 54.3318,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "a0eff49fada14fb4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 14.7436,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "1e8424cdff6d46a0",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.93374374304268,
    "Accuracy_div_100": 0.87934,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 18.9292,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "2f9201a5b28d44ab",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": "None",
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 1.2094,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "d0742397ce5c4570",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23098133171213,
    "Accuracy_div_100": 0.90231,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.13778,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "571dd88818e64a78",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 26.2901,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "00afdb9b47ef473e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.79118282730964,
    "Accuracy_div_100": 0.90791,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.733,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "3c01d1e7cdd3487b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.092,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "acafc2174e8e4e85",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 14.5634,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "0195dd329a3b4dc8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": "None",
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 1.29439,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "60877987aac14cb1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 5.98684,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "465594a2b9af414f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.94051065318,
    "Accuracy_div_100": 0.89941,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 7.63646,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "add2641dc8434c05",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 5.9642,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "3a4557cb252a402b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.08646571797165,
    "Accuracy_div_100": 0.90086,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.8954,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.5.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.11-linuxkit-glibc2.35)",
    "uid": "6cc08b55da25420e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/macbook_pro_m1_2-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.6396,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "e9c9e05f4af64ce8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.89212297504716,
    "Accuracy_div_100": 0.87892,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 19.115,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "782038ffef5641d3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.03328,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "82e19ab1b45246a5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.26941848776319,
    "Accuracy_div_100": 0.90269,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 5.47764,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "16fe5dd4c1be4bb4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 21.1835,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "99829231a3164bf1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.40462194474198,
    "Accuracy_div_100": 0.90405,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 27.4951,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "4e0ea683f7c949c4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.79584822581347,
    "Accuracy_div_100": 0.90796,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 13.3361,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "e7da747898d74221",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 26.2284,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "41ce9d99508444f8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 12.135,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "f3b4b8b311854f3a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.0909,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "8dc57bf47f3943cd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 5.59124,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "5c16156fec844250",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.0299132434367,
    "Accuracy_div_100": 0.9003,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 7.29728,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "58c181f43a58460d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 7.17755,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "a53926ef4f3741db",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.15626980699892,
    "Accuracy_div_100": 0.90156,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 7.32305,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.2xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "ca47bc9760a34b8c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.2xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.42042174998099,
    "Accuracy_div_100": 0.8842,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.2359,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "736ff9fa9091402e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 87.89212297504716,
    "Accuracy_div_100": 0.87892,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 13.0945,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "f661d57e83a14474",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.4308347276475,
    "Accuracy_div_100": 0.90431,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 20.5071,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "4196d64d9377421e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.40462194474198,
    "Accuracy_div_100": 0.90405,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 27.1278,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "7d30f0d9f6f64441",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.7887526723603,
    "Accuracy_div_100": 0.90789,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 10.6813,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "680d17d5b875497f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 13.3146,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "83fc4381ca8244a3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 88.31078542237867,
    "Accuracy_div_100": 0.88311,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.25857,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "299f195e954c4dac",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 4.54128,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "d278b57f3a9f4e1f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1810702860831,
    "Accuracy_div_100": 0.90181,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "CTuning",
    "Platform": "t3.xlarge-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 4.03085,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance t3.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-1017-aws-glibc2.35)",
    "uid": "af08e9e071574ef1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/t3.xlarge-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.68036,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1 (Tejasvis)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": " (darwin-23.3.0)",
    "uid": "6df58629604044fa",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23098133171213,
    "Accuracy_div_100": 0.90231,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 13.2117,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1 (Tejasvis)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": " (darwin-23.3.0)",
    "uid": "b5ee5ce4c97c4bff",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89066465550044,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 30.1667,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1 (Tejasvis)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": " (darwin-23.3.0)",
    "uid": "fd0042c68e9e4877",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 89.65191480026783,
    "Accuracy_div_100": 0.89652,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "CTuning",
    "Platform": "Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 2.69294,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1 (Tejasvis)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": " (darwin-23.3.0)",
    "uid": "539f33e00a5c4e76",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.17832662822171,
    "Accuracy_div_100": 0.90178,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "CTuning",
    "Platform": "Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.79108,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1 (Tejasvis)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": " (darwin-23.3.0)",
    "uid": "7cd964bf069748ba",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.1356467730578,
    "Accuracy_div_100": 0.90136,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "CTuning",
    "Platform": "Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 9.88061,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1 (Tejasvis)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural Magic inference implementation with CM API, DeepSparse v1.6.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": " (darwin-23.3.0)",
    "uid": "9e08843912124589",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/Tejasvis_MBP-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "version": "v4.0"
  }
]
