[
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 3954.44,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "8e4430098a5b49d8",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/server",
    "version": "v3.1",
    "Result_Power": 621.153666666667,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.51288910155475,
    "Accuracy_div_100": 0.90513,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 3954.44,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "8e4430098a5b49d8",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/server",
    "version": "v3.1",
    "Result_Power": 621.153666666667,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.86854261300948,
    "Accuracy_div_100": 0.90869,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 1521.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "48f7f899741646a6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99.9/server",
    "version": "v3.1",
    "Result_Power": 620.6488333333333,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.86854261300948,
    "Accuracy_div_100": 0.90869,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 1521.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "48f7f899741646a6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99.9/server",
    "version": "v3.1",
    "Result_Power": 620.6488333333333,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.91678269111374,
    "Accuracy_div_100": 0.90917,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/bert_pruned_83.2_mp/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert_pruned_83.2_mp",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.8.3.7-aic100",
    "Result": 12498.2,
    "Result_Power": 695.6283333333336,
    "Result_Power_Units": "Watts",
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE R282-Z93 (8x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "73ba2ca9f5574fbf",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/bert_pruned_83.2_mp/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 86.13436789084363,
    "Accuracy_div_100": 0.86134,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/distilbert_mp/server",
    "MlperfModel": "bert-99",
    "Model": "distilbert_mp",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.8.3.7-aic100",
    "Result": 21506,
    "Result_Power": 551.6442000000006,
    "Result_Power_Units": "Watts",
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE R282-Z93 (8x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "bf56f497805649ae",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/distilbert_mp/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.09233322361673,
    "Accuracy_div_100": 0.90092,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/bert_pruned_82.6_mp/server",
    "MlperfModel": "bert-99",
    "Model": "bert_pruned_82.6_mp",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.8.3.7-aic100",
    "Result": 16698.9,
    "Result_Power": 777.138833333333,
    "Result_Power_Units": "Watts",
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE R282-Z93 (8x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "e3762c107c2942c1",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/bert_pruned_82.6_mp/server",
    "version": "v3.0"
  }
]
