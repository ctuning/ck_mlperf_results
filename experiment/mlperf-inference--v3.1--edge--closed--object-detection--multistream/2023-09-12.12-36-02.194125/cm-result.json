[
  {
    "Accuracy": 37.572,
    "Accuracy_div_100": 0.37572,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/IEI/results/NF5468M6_A40x1_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "IEI",
    "Platform": "NF5468M6_A40x1_TRT",
    "Result": 26.411267,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "NF5468M6 (1x A40, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "d9b3d5e2f6c248e4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/IEI/results/NF5468M6_A40x1_TRT/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.311,
    "Accuracy_div_100": 0.37311,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/TTA/results/KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "TTA",
    "Platform": "KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 120.726896,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "KR580S1",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "tensorrt 8.6.1, ",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6140 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-4.18.0-448.el8.x86_64-glibc2.35)",
    "uid": "6eeefa95024a4c32",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/TTA/results/KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.339,
    "Accuracy_div_100": 0.37339,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ConnectTechInc/results/Orin_NX_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ConnectTechInc",
    "Platform": "Orin_NX_TRT",
    "Result": 214.85654,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "NVIDIA Orin NX 16G (TensorRT) + CTI Hadron Carrier (NGX012)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "CTI Hadron Carrier for Orin-NX/Orin-NANO (NGX012) is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "CTI Jetson BSP ORIN-NX-NANO-35.3.1-V002-MLPERF (Jetson r35.3.1 L4T)",
    "uid": "7748f7392ade44fc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ConnectTechInc/results/Orin_NX_TRT/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.373,
    "Accuracy_div_100": 0.37373,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT",
    "Result": 82.920591,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "cab5c52ea5fc428d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_TRT/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.374,
    "Accuracy_div_100": 0.37374,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_NX_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT",
    "Result": 217.146737,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "NVIDIA Orin NX 16G (TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "777e8da721f24b0a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.339,
    "Accuracy_div_100": 0.37339,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/aws_t4-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "aws_t4-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 102.459942,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-1028-aws-glibc2.35)",
    "uid": "453cf8198a61434a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/aws_t4-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-cpu-pytorch-v2.0.1-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-cpu-pytorch-v2.0.1-default_config",
    "Result": 3673.790808,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Pytorch v2.0.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "ae040e088619457c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-cpu-pytorch-v2.0.1-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.339,
    "Accuracy_div_100": 0.37339,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/aws_g4dn.xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "aws_g4dn.xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 102.459942,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-1029-aws-glibc2.35)",
    "uid": "1f110388273d43fa",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/aws_g4dn.xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.411,
    "Accuracy_div_100": 0.37411,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/rigel-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "rigel-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 4.584035,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "One Stop Systems Rigel Edge Supercomputer",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA HGX A100 SXM",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7502 32-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-78-generic-glibc2.35)",
    "uid": "ff992d259cc64dcc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/rigel-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.572,
    "Accuracy_div_100": 0.37572,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/amd_ryzen_workstation-cpp-cpu-onnxruntime-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-cpp-cpu-onnxruntime-vdefault-default_config",
    "Result": 3801.098688,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "cTuning/MLCommons C++ Modular Inference Library (MIL), Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "942f9a5a3a4a4e84",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-cpp-cpu-onnxruntime-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.392,
    "Accuracy_div_100": 0.37392,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/amd_ryzen_workstation_triton-nvidia_original-gpu-tensorrt-vdefault-using_triton/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation_triton-nvidia_original-gpu-tensorrt-vdefault-using_triton",
    "Result": 14.105047,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC (Nvidia Triton server)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.19.0-46-generic-glibc2.31)",
    "uid": "106b46e33b654b1d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation_triton-nvidia_original-gpu-tensorrt-vdefault-using_triton/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.573,
    "Accuracy_div_100": 0.37573,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/amd_ryzen_workstation-cpp-gpu-onnxruntime-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-cpp-gpu-onnxruntime-vdefault-default_config",
    "Result": 150.843968,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "cTuning/MLCommons C++ Modular Inference Library (MIL), Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "4ce03aadb07c4c92",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-cpp-gpu-onnxruntime-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.343,
    "Accuracy_div_100": 0.37343,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_L40_PCIe_48GBx2_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "Lenovo_L40_PCIe_48GBx2_TRT",
    "Result": 10.899652,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Lenovo ThinkEdge SE450 Edge Server (2x NVIDIA L40 PCIe 48GB)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40-PCIE-48GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c4fc8d31920844c5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/Lenovo_L40_PCIe_48GBx2_TRT/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q5/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q5",
    "Result": 16.493722,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "GIGABYTE R282-Z93 (5x QAIC100 Pro)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-148-generic #165-Ubuntu SMP Tue Apr 18 08:53:12 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "6bd27adcf5fa44b0",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/r282_z93_q5/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.437,
    "Accuracy_div_100": 0.37437,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR7620_L4x1_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XR7620_L4x1_TRT",
    "Result": 40.705652,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Dell PowerEdge XR7620 (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "615420e5f8a94d18",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR7620_L4x1_TRT/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.457,
    "Accuracy_div_100": 0.37457,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_L4x1_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XR4520c_L4x1_TRT",
    "Result": 40.136794,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Dell PowerEdge XR4520c (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "c997d164835148ef",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR4520c_L4x1_TRT/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/xr4520c_q2_std/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "xr4520c_q2_std",
    "Result": 37.044475,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Dell PowerEdge XR4520c (2x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Dell XR4000r chassis. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "d01b9368777c42ae",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/xr4520c_q2_std/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.417,
    "Accuracy_div_100": 0.37417,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40x4_edge_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_L40x4_edge_TRT",
    "Result": 10.826322,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Dell PowerEdge R760xa (4x L40, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "8ac12a5b6d894c98",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_L40x4_edge_TRT/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.482,
    "Accuracy_div_100": 0.37482,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nutanix",
    "Platform": "NX_3155G_G8_A100_PCIe_80GBx2_TRT",
    "Result": 13.069697,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "NX_3155G_G8_A100_PCIe_80GBx2",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354 CPU @ 3.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "70ddb5d526474e88",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.351,
    "Accuracy_div_100": 0.37351,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_L40x1_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5300G6_L40x1_TRT",
    "Result": 16.789801,
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "H3C UniServer R5300 G6 (1x L40, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "84e2b73957ac48fe",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/H3C/results/R5300G6_L40x1_TRT/retinanet/MultiStream",
    "version": "v3.1"
  }
]
