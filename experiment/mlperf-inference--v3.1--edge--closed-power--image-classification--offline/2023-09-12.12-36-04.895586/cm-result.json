[
  {
    "Accuracy": 75.976,
    "Accuracy_div_100": 0.75976,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 8.458834893960951,
    "Location": "closed/Krai/results/eb6-kilt-snpe_dsp/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Krai",
    "Platform": "eb6-kilt-snpe_dsp",
    "Result": 105.985,
    "Result_Power": 12.529503333333327,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Thundercomm TurboX EB6 Edge AI Box",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Hexagon 698 DSP",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with Snapdragon DSP support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Optional 5G and SSD modules not installed. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Fri May 6 18:00:47 CST 2022)",
    "uid": "756bba1c719945e4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Krai/results/eb6-kilt-snpe_dsp/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.976,
    "Accuracy_div_100": 0.75976,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 8.458834893960951,
    "Location": "closed/Krai/results/eb6-kilt-snpe_dsp/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Krai",
    "Platform": "eb6-kilt-snpe_dsp",
    "Result": 105.985,
    "Result_Power": 12.529503333333327,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Thundercomm TurboX EB6 Edge AI Box",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Hexagon 698 DSP",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with Snapdragon DSP support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Optional 5G and SSD modules not installed. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Fri May 6 18:00:47 CST 2022)",
    "uid": "756bba1c719945e4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Krai/results/eb6-kilt-snpe_dsp/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.452,
    "Accuracy_div_100": 0.76452,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.5259173300441582,
    "Location": "closed/Krai/results/eb6-kilt-snpe_gpu/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Krai",
    "Platform": "eb6-kilt-snpe_gpu",
    "Result": 21.0084,
    "Result_Power": 13.76771833333333,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Thundercomm TurboX EB6 Edge AI Box",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Adreno 650 GPU",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with Snapdragon GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Optional 5G and SSD modules not installed. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Fri May 6 18:00:47 CST 2022)",
    "uid": "b2a680e32505451f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Krai/results/eb6-kilt-snpe_gpu/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.452,
    "Accuracy_div_100": 0.76452,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.5259173300441582,
    "Location": "closed/Krai/results/eb6-kilt-snpe_gpu/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Krai",
    "Platform": "eb6-kilt-snpe_gpu",
    "Result": 21.0084,
    "Result_Power": 13.76771833333333,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Thundercomm TurboX EB6 Edge AI Box",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Adreno 650 GPU",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with Snapdragon GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Optional 5G and SSD modules not installed. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Fri May 6 18:00:47 CST 2022)",
    "uid": "b2a680e32505451f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Krai/results/eb6-kilt-snpe_gpu/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.99,
    "Accuracy_div_100": 0.7599,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 10.920063836162354,
    "Location": "closed/Krai/results/eb6-kilt-snpe_aip/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Krai",
    "Platform": "eb6-kilt-snpe_aip",
    "Result": 128.469,
    "Result_Power": 11.764491666666661,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Thundercomm TurboX EB6 Edge AI Box",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM NPU 230 AIP",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with Snapdragon AIP support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Optional 5G and SSD modules not installed. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Fri May 6 18:00:47 CST 2022)",
    "uid": "cdd4105d58ce42fc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Krai/results/eb6-kilt-snpe_aip/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.99,
    "Accuracy_div_100": 0.7599,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 10.920063836162354,
    "Location": "closed/Krai/results/eb6-kilt-snpe_aip/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Krai",
    "Platform": "eb6-kilt-snpe_aip",
    "Result": 128.469,
    "Result_Power": 11.764491666666661,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Thundercomm TurboX EB6 Edge AI Box",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM NPU 230 AIP",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with Snapdragon AIP support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Optional 5G and SSD modules not installed. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Fri May 6 18:00:47 CST 2022)",
    "uid": "cdd4105d58ce42fc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Krai/results/eb6-kilt-snpe_aip/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.004,
    "Accuracy_div_100": 0.76004,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 112.51690373727973,
    "Location": "closed/NVIDIA/results/Orin_NX_TRT_MaxQ/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT_MaxQ",
    "Result": 1681.87,
    "Result_Power": 14.947709580838326,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin NX 16G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario; WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "f771addf0e6e43d2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT_MaxQ/resnet50/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.004,
    "Accuracy_div_100": 0.76004,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 112.51690373727973,
    "Location": "closed/NVIDIA/results/Orin_NX_TRT_MaxQ/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT_MaxQ",
    "Result": 1681.87,
    "Result_Power": 14.947709580838326,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin NX 16G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario; WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "f771addf0e6e43d2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT_MaxQ/resnet50/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.018,
    "Accuracy_div_100": 0.76018,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 149.62871307936635,
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 3526.29,
    "Result_Power": 23.56693396226417,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario. WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "f1694c6b4dca4b83",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/resnet50/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.018,
    "Accuracy_div_100": 0.76018,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 149.62871307936635,
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 3526.29,
    "Result_Power": 23.56693396226417,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario. WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "f1694c6b4dca4b83",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/resnet50/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.028,
    "Accuracy_div_100": 0.76028,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 107.0411345931278,
    "Location": "closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "CTuning",
    "Platform": "orin-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 3129.69,
    "Result_Power": 29.23819905213272,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (non MaxN image)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "e5f3915503124bd4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.028,
    "Accuracy_div_100": 0.76028,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 107.0411345931278,
    "Location": "closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "CTuning",
    "Platform": "orin-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 3129.69,
    "Result_Power": 29.23819905213272,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (non MaxN image)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "e5f3915503124bd4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.158,
    "Accuracy_div_100": 0.76158,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 74.12001261528351,
    "Location": "closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 45772.1,
    "Result_Power": 617.5403697996917,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "7a7c374df51446cc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.158,
    "Accuracy_div_100": 0.76158,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 74.12001261528351,
    "Location": "closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 45772.1,
    "Result_Power": 617.5403697996917,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "7a7c374df51446cc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.948,
    "Accuracy_div_100": 0.75948,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 92.35382329499049,
    "Location": "closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 6341.65,
    "Result_Power": 68.6668918918919,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (64K page size)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "214147348e414164",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.948,
    "Accuracy_div_100": 0.75948,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 92.35382329499049,
    "Location": "closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 6341.65,
    "Result_Power": 68.6668918918919,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (64K page size)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "214147348e414164",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.456,
    "Accuracy_div_100": 0.76456,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.9602317368277855,
    "Location": "closed/CTuning/results/nvidia_orin_maxq-reference-cpu-onnxruntime-v1.15.1-default_config/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_maxq-reference-cpu-onnxruntime-v1.15.1-default_config",
    "Result": 28.9732,
    "Result_Power": 30.173133097762054,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (non MaxN image)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "e4ef3d21f53d4ad7",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_maxq-reference-cpu-onnxruntime-v1.15.1-default_config/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.456,
    "Accuracy_div_100": 0.76456,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.9602317368277855,
    "Location": "closed/CTuning/results/nvidia_orin_maxq-reference-cpu-onnxruntime-v1.15.1-default_config/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_maxq-reference-cpu-onnxruntime-v1.15.1-default_config",
    "Result": 28.9732,
    "Result_Power": 30.173133097762054,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (non MaxN image)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "e4ef3d21f53d4ad7",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_maxq-reference-cpu-onnxruntime-v1.15.1-default_config/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.948,
    "Accuracy_div_100": 0.75948,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 92.35382329499049,
    "Location": "closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 6341.65,
    "Result_Power": 68.6668918918919,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (4K page size)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Jetson Linux 35.3.1, Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "27a47329ec0342cc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.948,
    "Accuracy_div_100": 0.75948,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 92.35382329499049,
    "Location": "closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 6341.65,
    "Result_Power": 68.6668918918919,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (4K page size)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Jetson Linux 35.3.1, Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "27a47329ec0342cc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.936,
    "Accuracy_div_100": 0.75936,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 172.91108943269694,
    "Location": "closed/Lenovo/results/se450_q4_std/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "se450_q4_std",
    "Result": 80092.7,
    "Result_Power": 463.2016388467374,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo ThinkEdge SE450 Edge Server (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5318N CPU @ 2.10 GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "84bd73d40d88494d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/se450_q4_std/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.936,
    "Accuracy_div_100": 0.75936,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 172.91108943269694,
    "Location": "closed/Lenovo/results/se450_q4_std/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "se450_q4_std",
    "Result": 80092.7,
    "Result_Power": 463.2016388467374,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo ThinkEdge SE450 Edge Server (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5318N CPU @ 2.10 GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "84bd73d40d88494d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/se450_q4_std/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.998,
    "Accuracy_div_100": 0.75998,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 312.01743779916967,
    "Location": "closed/Qualcomm/results/gloria_highend/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Qualcomm",
    "Platform": "gloria_highend",
    "Result": 9808.25,
    "Result_Power": 31.434941807044417,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Foxconn Gloria (Highend)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 20W Accelerator TDP constraints; optional SSD and 5G module not installed",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Wed Jun 8 17:13:04 UTC 2022)",
    "uid": "6bae68d90f0042ee",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/gloria_highend/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.998,
    "Accuracy_div_100": 0.75998,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 312.01743779916967,
    "Location": "closed/Qualcomm/results/gloria_highend/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Qualcomm",
    "Platform": "gloria_highend",
    "Result": 9808.25,
    "Result_Power": 31.434941807044417,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Foxconn Gloria (Highend)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 20W Accelerator TDP constraints; optional SSD and 5G module not installed",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Wed Jun 8 17:13:04 UTC 2022)",
    "uid": "6bae68d90f0042ee",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/gloria_highend/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.936,
    "Accuracy_div_100": 0.75936,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 213.39397247674762,
    "Location": "closed/Qualcomm/results/r282_z93_q5e/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q5e",
    "Result": 106349,
    "Result_Power": 498.36927803379393,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE R282-Z93 (5x QAIC100 Pro, EE)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-148-generic #165-Ubuntu SMP Tue Apr 18 08:53:12 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "cca4f7af800f49f2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/r282_z93_q5e/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.936,
    "Accuracy_div_100": 0.75936,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 213.39397247674762,
    "Location": "closed/Qualcomm/results/r282_z93_q5e/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q5e",
    "Result": 106349,
    "Result_Power": 498.36927803379393,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE R282-Z93 (5x QAIC100 Pro, EE)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-148-generic #165-Ubuntu SMP Tue Apr 18 08:53:12 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "cca4f7af800f49f2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/r282_z93_q5e/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.962,
    "Accuracy_div_100": 0.75962,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 162.49850024025199,
    "Location": "closed/SiMa/results/davinci_hhhl/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "SiMa",
    "Platform": "davinci_hhhl",
    "Result": 2952.58,
    "Result_Power": 18.169890772128035,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "MLSoC HHHL",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "DaVinci",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "SiMa SDK Version 0.7",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "4-core Cortex-A65 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "HHHL with 2 ethernet ports powered over USB-C. Production Palette Compiler v1",
    "number_of_nodes": 1,
    "operating_system": "Yocto Poky Linux 3.4.4",
    "uid": "4acaac0613cd4833",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/SiMa/results/davinci_hhhl/resnet50/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.962,
    "Accuracy_div_100": 0.75962,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 162.49850024025199,
    "Location": "closed/SiMa/results/davinci_hhhl/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "SiMa",
    "Platform": "davinci_hhhl",
    "Result": 2952.58,
    "Result_Power": 18.169890772128035,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "MLSoC HHHL",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "DaVinci",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "SiMa SDK Version 0.7",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "4-core Cortex-A65 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "HHHL with 2 ethernet ports powered over USB-C. Production Palette Compiler v1",
    "number_of_nodes": 1,
    "operating_system": "Yocto Poky Linux 3.4.4",
    "uid": "4acaac0613cd4833",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/SiMa/results/davinci_hhhl/resnet50/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.078,
    "Accuracy_div_100": 0.76078,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 37.1578333976062,
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": 12432.5,
    "Result_Power": 334.58624637681197,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2,",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "665c378b6a9b446b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/resnet50/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 76.078,
    "Accuracy_div_100": 0.76078,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 37.1578333976062,
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": 12432.5,
    "Result_Power": 334.58624637681197,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2,",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "665c378b6a9b446b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/resnet50/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.936,
    "Accuracy_div_100": 0.75936,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 188.28663124044576,
    "Location": "closed/HPE/results/e920d_q4_std/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "e920d_q4_std",
    "Result": 79948.9,
    "Result_Power": 424.6127272727274,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant e920d (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8351N CPU @ 2.40 GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints; Edgeline EL8000 chassis. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "d8b7921f2eee4210",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/e920d_q4_std/resnet50/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 75.936,
    "Accuracy_div_100": 0.75936,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 188.28663124044576,
    "Location": "closed/HPE/results/e920d_q4_std/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "e920d_q4_std",
    "Result": 79948.9,
    "Result_Power": 424.6127272727274,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant e920d (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8351N CPU @ 2.40 GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints; Edgeline EL8000 chassis. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "d8b7921f2eee4210",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/e920d_q4_std/resnet50/offline",
    "version": "v3.1"
  }
]
