[
  {
    "Accuracy": 37.572,
    "Accuracy_div_100": 0.37572,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/IEI/results/NF5468M6_A40x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "IEI",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 2453,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "ae69de68c3fa44fc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/IEI/results/NF5468M6_A40x8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.355,
    "Accuracy_div_100": 0.37355,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/7920t-kilt-tensorrt/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Krai",
    "Platform": "7920t-kilt-tensorrt",
    "Result": 420.651,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell Precision 7920 Tower (2x NVIDIA RTX A5000 GPU)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with TensorRT support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux chai 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "5cf9486050704780",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Krai/results/7920t-kilt-tensorrt/retinanet/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.356,
    "Accuracy_div_100": 0.37356,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 13020.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "adb9a31ef6b44ef7",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.434,
    "Accuracy_div_100": 0.37434,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT",
    "Result": 8402.57,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-521GE-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "f7e79943b2df44cf",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.353,
    "Accuracy_div_100": 0.37353,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 12996.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "cdc726275cb9457e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.406,
    "Accuracy_div_100": 0.37406,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 1049.36,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6098c41995d44cc8",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.42,
    "Accuracy_div_100": 0.3742,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 199.743,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASROCKRACK 1U1G-MILAN (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2971ce26390f4922",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/L4x1_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.426,
    "Accuracy_div_100": 0.37426,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1731.49,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "d5ffb7a653a94a72",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.42,
    "Accuracy_div_100": 0.3742,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 8402.57,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0c5b5479cbd94615",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.439,
    "Accuracy_div_100": 0.37439,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 12884.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2f5bb4f8d2a940c6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.409,
    "Accuracy_div_100": 0.37409,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 1621.29,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "aaf9f04b80294199",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.42,
    "Accuracy_div_100": 0.3742,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 144.896,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Google Cloud Platform (g2.standard.4)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.20GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-1030-gcp-glibc2.35)",
    "uid": "139902e3a9f64a7a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.418,
    "Accuracy_div_100": 0.37418,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 1601.45,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "39388c729fa74a56",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.413,
    "Accuracy_div_100": 0.37413,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "H100_PCIe_80GBx8_TRT",
    "Result": 8402.57,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8xH100-PCIe-80GB, TensorRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "414219551fa0478a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.458,
    "Accuracy_div_100": 0.37458,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/PRIMERGY_CDI_V1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Fujitsu",
    "Platform": "PRIMERGY_CDI_V1_TRT",
    "Result": 2916.47,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "PRIMERGY_CDI_V1 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIE-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "GPUs are installed in an external PCIe box.",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "323feec56a9c4d34",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Fujitsu/results/PRIMERGY_CDI_V1_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/sr665_q5_pro/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "sr665_q5_pro",
    "Result": 1386.48,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo ThinkSystem SR665v1 (5x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 75F3 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS (Jammy Jellyfish) (Linux kernel: 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux",
    "uid": "b62dafbf58654e9c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/sr665_q5_pro/retinanet/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.362,
    "Accuracy_div_100": 0.37362,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_H100_PCIe_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "Lenovo_H100_PCIe_80GBx8_TRT",
    "Result": 8801.85,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo ThinkSystem SR675 V3 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "f025bba3ec6e4b75",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/Lenovo_H100_PCIe_80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16",
    "Result": 4578.88,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "463b9cb48bf34ef4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/g292_z43_q16/retinanet/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.452,
    "Accuracy_div_100": 0.37452,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIe_80GBx4_TRT",
    "Result": 2703.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "4583060b992142fe",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.427,
    "Accuracy_div_100": 0.37427,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx2_TRT",
    "Result": 2248.32,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0df3c5f14bc947e9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.419,
    "Accuracy_div_100": 0.37419,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 6656.63,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "9a26245e62084c70",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.331,
    "Accuracy_div_100": 0.37331,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 4280.81,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "a064657a23ea4277",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.344,
    "Accuracy_div_100": 0.37344,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 4354.53,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "932058a7a1244c29",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.35,
    "Accuracy_div_100": 0.3735,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 12484.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "c4d26922177b48c6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 199.743,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge Server R760 (1x Intel Xeon Platinum 8480+)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 224,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "f85229dfaeec43f6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.419,
    "Accuracy_div_100": 0.37419,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40x4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_L40x4_TRT",
    "Result": 1901.51,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "90054a1d1d094f0a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_L40x4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.397,
    "Accuracy_div_100": 0.37397,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 6756.77,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x NVIDIA H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "6bdf2a3549e6437d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.436,
    "Accuracy_div_100": 0.37436,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 3864.53,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ede7ad7221b04f27",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.369,
    "Accuracy_div_100": 0.37369,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 4204.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0c221e0fc39847e0",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.437,
    "Accuracy_div_100": 0.37437,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 3100.41,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "971aa5cf27a4485a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.413,
    "Accuracy_div_100": 0.37413,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 1280.38,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "191571a612f143b2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.394,
    "Accuracy_div_100": 0.37394,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 5264.69,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e0c42305bf7c4c86",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 214.581,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "0a3219e2acda4160",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.344,
    "Accuracy_div_100": 0.37344,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Oracle",
    "Platform": "OCI-A100_A100-SXM-80GBx8_TRT",
    "Result": 5603.34,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "BM.GPU.A100-v2.8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7J13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "047d03b63028424d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.324,
    "Accuracy_div_100": 0.37324,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/A10x4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Oracle",
    "Platform": "A10x4_TRT",
    "Result": 855.004,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "BM.GPU.A10.4",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A10-PCI-24GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "933f5b289c4e4222",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/A10x4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.33,
    "Accuracy_div_100": 0.3733,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 12884.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f937329163474d0d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.353,
    "Accuracy_div_100": 0.37353,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT",
    "Result": 12884.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD0",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3f99d6f5faca4a46",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.326,
    "Accuracy_div_100": 0.37326,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_L40x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5350G6_L40x8_TRT",
    "Result": 4874.86,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5350 G6 (8x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9754 128-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "abb3f3ce83844a10",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/H3C/results/R5350G6_L40x8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.362,
    "Accuracy_div_100": 0.37362,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_L40x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5300G6_L40x8_TRT",
    "Result": 4904.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G6 (8x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "2979f37ec499439b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/H3C/results/R5300G6_L40x8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.351,
    "Accuracy_div_100": 0.37351,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54Q_2U_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54Q_2U_H100_PCIe_80GBx2_TRT",
    "Result": 2001.26,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54Q_2U (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "642782836cdd4eae",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54Q_2U_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.318,
    "Accuracy_div_100": 0.37318,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4004.73,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54U-3U (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "4a65e17077cb44f1",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 211.654,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+ 56-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "0410c6db6b71416a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.336,
    "Accuracy_div_100": 0.37336,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54Q_2U_L4_PCIe_24GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54Q_2U_L4_PCIe_24GBx4_TRT",
    "Result": 799.336,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54Q_2U (4x L4-PCIe-24GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4-PCIe-24GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "aa0e49738c534faf",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54Q_2U_L4_PCIe_24GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.358,
    "Accuracy_div_100": 0.37358,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_XL675d_Gen10_Plus_A100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_XL675d_Gen10_Plus_A100_SXM_80GBx8_TRT",
    "Result": 5603.34,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant XL675d Gen10 Plus (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.1",
    "uid": "2f66df7f49c547b9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/HPE_ProLiant_XL675d_Gen10_Plus_A100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.335,
    "Accuracy_div_100": 0.37335,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL320_Gen11_L4x4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL320_Gen11_L4x4_TRT",
    "Result": 799.336,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL320 Gen11 (4x L4-PCIe-24GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4-PCIe-24GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5412U",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "39f28d63825a4d13",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/HPE_ProLiant_DL320_Gen11_L4x4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/dl385_q8_std/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "dl385_q8_std",
    "Result": 2229.07,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.15.0-75-generic #82~20.04.1-Ubuntu SMP Wed Jun 7 19:37:37 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "1f575865a7c14c8d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/dl385_q8_std/retinanet/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.323,
    "Accuracy_div_100": 0.37323,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_Gen11_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_Gen11_H100_PCIe_80GBx4_TRT",
    "Result": 4004.73,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "566ffb9de1fa4d00",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_Gen11_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 199.743,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "HPE ProLiant DL380a Gen11. N/A",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux 8.8 (Ootpa)",
    "uid": "08c7f6f332fe42a2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "version": "v3.1"
  }
]
