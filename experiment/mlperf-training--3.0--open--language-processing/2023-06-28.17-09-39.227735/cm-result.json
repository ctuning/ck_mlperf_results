[
  {
    "Accuracy": 0.72,
    "Accuracy_Metric": "Mask-LM accuracy",
    "Benchmark": "language-processing",
    "Dataset": "Wikipedia",
    "Model_ID": "bert",
    "Organization": "Intel",
    "Result": 31.060012500000003,
    "Result_Units": "min.",
    "Task": "language-processing",
    "_Accuracy": 0.72,
    "_Accuracy_Metric": "Mask-LM accuracy",
    "_Dataset": "Wikipedia",
    "_Model_ID": "bert",
    "_Organization": "Intel",
    "_Result": 31.060012500000003,
    "_Result_Units": "min.",
    "_System": "16-nodes-SPR-pytorch-open",
    "_Task": "language-processing",
    "_version": "3.0",
    "accelerator_model_name": "N/A",
    "accelerators_count": 0,
    "availability": "available",
    "bert": 31.060012500000003,
    "code_url": "https://github.com/mlcommons/training_results_v3.0/blob/master/Intel/benchmarks",
    "details_url": "https://github.com/mlcommons/training_results_v3.0/blob/main/Intel/systems/16-nodes-SPR-pytorch-open.json",
    "division": "open",
    "dlrm_dcnv2": "",
    "framework": "Pytorch",
    "git_url": "https://github.com/mlcommons/training_results_v3.0",
    "gpt3": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+ @ 2.00GHz",
    "host_processors_count": 32,
    "notes": "We perform LAMB over a fused parameter instead of individual parameters (one fused param for each datatype and weight_decay value). No change in model or any other computation compared to closed division",
    "submitter": "Intel",
    "system": "16-nodes-SPR-pytorch-open",
    "uid": "a4a729d8d0d74fe8",
    "unet3d": "",
    "version": "3.0"
  }
]
