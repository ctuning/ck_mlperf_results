[
  {
    "Accuracy": 42.9603,
    "Accuracy_div_100": 0.4296,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30x8_Inspur/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Moffett",
    "Platform": "Moffett_S30x8_Inspur",
    "Result": 170.586,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur NF5468M6 (8x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "13e0a3ab44e24bd4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Moffett/results/Moffett_S30x8_Inspur/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9604,
    "Accuracy_div_100": 0.4296,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30_H3C/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Moffett",
    "Platform": "Moffett_S30_H3C",
    "Result": 23.2809,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C R5300 G5 (1x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "d952c9c5762641b5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Moffett/results/Moffett_S30_H3C/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9604,
    "Accuracy_div_100": 0.4296,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30x4_H3C/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Moffett",
    "Platform": "Moffett_S30x4_H3C",
    "Result": 91.574,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C R5300 G5 (4x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "a29aa195339a4c8b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Moffett/results/Moffett_S30x4_H3C/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9177,
    "Accuracy_div_100": 0.42918,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/1-node-4S-SPR-PyTorch-INT8/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "1-node-4S-SPR-PyTorch-INT8",
    "Result": 2.81426,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-4S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 4,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "7ed3bb418af044cf",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Supermicro/results/1-node-4S-SPR-PyTorch-INT8/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.18328497411034,
    "Accuracy_div_100": 0.90183,
    "Availability": "rdi",
    "Division": "open",
    "Location": "open/NVIDIA/results/L4x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 4609.04,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA L4 (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "052c17c80c2d4dc2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/NVIDIA/results/L4x1_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.79625788222037,
    "Accuracy_div_100": 0.90796,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_MiniLM",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-Neural_Engine-INT8",
    "Result": 6543.62,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "b6d1922156774da4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Intel/results/1-node-2S-SPR-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "version": "v3.1"
  }
]
