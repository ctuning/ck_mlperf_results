[
  {
    "Accuracy": 90.554,
    "Accuracy_div_100": 0.90554,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 8.013792756286016,
    "Location": "closed/NVIDIA/results/Orin_NX_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT_MaxQ",
    "Result": 136.59,
    "Result_Power": 17.04436390532546,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin NX 16G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario; WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "4731cd9b2440441e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT_MaxQ/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.554,
    "Accuracy_div_100": 0.90554,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 8.013792756286016,
    "Location": "closed/NVIDIA/results/Orin_NX_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT_MaxQ",
    "Result": 136.59,
    "Result_Power": 17.04436390532546,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin NX 16G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario; WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "4731cd9b2440441e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT_MaxQ/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 93.3309749976416,
    "Accuracy_div_100": 0.93331,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 9.472090093011758,
    "Location": "closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "orin-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 267.917,
    "Result_Power": 28.284887218045107,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (non MaxN image)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "10c7286414534d63",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 93.3309749976416,
    "Accuracy_div_100": 0.93331,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 9.472090093011758,
    "Location": "closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "orin-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 267.917,
    "Result_Power": 28.284887218045107,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (non MaxN image)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "10c7286414534d63",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35921728409352,
    "Accuracy_div_100": 0.90359,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 6.629093827678771,
    "Location": "closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 4144.88,
    "Result_Power": 625.2558958652365,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "0f731f4b4aba4571",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35921728409352,
    "Accuracy_div_100": 0.90359,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 6.629093827678771,
    "Location": "closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 4144.88,
    "Result_Power": 625.2558958652365,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "0f731f4b4aba4571",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.011735903672010228,
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-cpu-pytorch-v2.0.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-cpu-pytorch-v2.0.1-default_config",
    "Result": 3.97544,
    "Result_Power": 338.7417033322541,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Pytorch v2.0.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "3b4f5a9de58048d1",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-cpu-pytorch-v2.0.1-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.011735903672010228,
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-cpu-pytorch-v2.0.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-cpu-pytorch-v2.0.1-default_config",
    "Result": 3.97544,
    "Result_Power": 338.7417033322541,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Pytorch v2.0.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "3b4f5a9de58048d1",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-cpu-pytorch-v2.0.1-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87410716832628,
    "Accuracy_div_100": 0.90874,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.01316456835098841,
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-cpu-tf-v2.13.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-cpu-tf-v2.13.0-default_config",
    "Result": 4.40691,
    "Result_Power": 334.75537385691223,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Tensorflow v2.13.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "df40882c5567438f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-cpu-tf-v2.13.0-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87410716832628,
    "Accuracy_div_100": 0.90874,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.01316456835098841,
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-cpu-tf-v2.13.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-cpu-tf-v2.13.0-default_config",
    "Result": 4.40691,
    "Result_Power": 334.75537385691223,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Tensorflow v2.13.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "df40882c5567438f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-cpu-tf-v2.13.0-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.89176721247637,
    "Accuracy_div_100": 0.90892,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.21927427127826854,
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-gpu-tf-v2.13.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-gpu-tf-v2.13.0-default_config",
    "Result": 105.426,
    "Result_Power": 480.7951219512199,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Tensorflow v2.13.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "6028ddbe836447af",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-gpu-tf-v2.13.0-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.89176721247637,
    "Accuracy_div_100": 0.90892,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.21927427127826854,
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-gpu-tf-v2.13.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-gpu-tf-v2.13.0-default_config",
    "Result": 105.426,
    "Result_Power": 480.7951219512199,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Tensorflow v2.13.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "6028ddbe836447af",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-gpu-tf-v2.13.0-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.55193225421755,
    "Accuracy_div_100": 0.90552,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 6.764263657677536,
    "Location": "closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 521.435,
    "Result_Power": 77.08673499267933,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (64K page size)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "8bf2d8af52eb428f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.55193225421755,
    "Accuracy_div_100": 0.90552,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 6.764263657677536,
    "Location": "closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 521.435,
    "Result_Power": 77.08673499267933,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (64K page size)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "8bf2d8af52eb428f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.14690920139281866,
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-gpu-pytorch-v2.0.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-gpu-pytorch-v2.0.1-default_config",
    "Result": 88.5494,
    "Result_Power": 602.7491754122935,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Pytorch v2.0.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "54b3e1e6dad34fa2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-gpu-pytorch-v2.0.1-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.14690920139281866,
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-gpu-pytorch-v2.0.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-gpu-pytorch-v2.0.1-default_config",
    "Result": 88.5494,
    "Result_Power": 602.7491754122935,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Pytorch v2.0.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "54b3e1e6dad34fa2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-gpu-pytorch-v2.0.1-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.88143498300359,
    "Accuracy_div_100": 0.90881,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.2734758893469749,
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-gpu-onnxruntime-v1.15.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-gpu-onnxruntime-v1.15.1-default_config",
    "Result": 149.105,
    "Result_Power": 545.2217391304347,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "bbc2ad38b7c84c94",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-gpu-onnxruntime-v1.15.1-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.88143498300359,
    "Accuracy_div_100": 0.90881,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.2734758893469749,
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-gpu-onnxruntime-v1.15.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-gpu-onnxruntime-v1.15.1-default_config",
    "Result": 149.105,
    "Result_Power": 545.2217391304347,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "bbc2ad38b7c84c94",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-gpu-onnxruntime-v1.15.1-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.55193225421755,
    "Accuracy_div_100": 0.90552,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 6.730969883779952,
    "Location": "closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 495.154,
    "Result_Power": 73.56354411764703,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (4K page size)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Jetson Linux 35.3.1, Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "e52e4808cc2f46d5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.55193225421755,
    "Accuracy_div_100": 0.90552,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 6.730969883779952,
    "Location": "closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 495.154,
    "Result_Power": 73.56354411764703,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (4K page size)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Jetson Linux 35.3.1, Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "e52e4808cc2f46d5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.013783209895416863,
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-cpu-onnxruntime-v1.15.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-cpu-onnxruntime-v1.15.1-default_config",
    "Result": 4.50217,
    "Result_Power": 326.64161934420247,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "a4bc3e3f1c5b4104",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-cpu-onnxruntime-v1.15.1-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.013783209895416863,
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-cpu-onnxruntime-v1.15.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-cpu-onnxruntime-v1.15.1-default_config",
    "Result": 4.50217,
    "Result_Power": 326.64161934420247,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "a4bc3e3f1c5b4104",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-cpu-onnxruntime-v1.15.1-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 6.577917797578938,
    "Location": "closed/Lenovo/results/se450_q4_std/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "se450_q4_std",
    "Result": 2972.69,
    "Result_Power": 451.91960305343514,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo ThinkEdge SE450 Edge Server (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5318N CPU @ 2.10 GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "ad085ee9cb544ca4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/se450_q4_std/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 6.577917797578938,
    "Location": "closed/Lenovo/results/se450_q4_std/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "se450_q4_std",
    "Result": 2972.69,
    "Result_Power": 451.91960305343514,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo ThinkEdge SE450 Edge Server (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5318N CPU @ 2.10 GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "ad085ee9cb544ca4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/se450_q4_std/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 12.057480383072207,
    "Location": "closed/Qualcomm/results/gloria_highend/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "gloria_highend",
    "Result": 371.142,
    "Result_Power": 30.78105775075988,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Foxconn Gloria (Highend)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 20W Accelerator TDP constraints; optional SSD and 5G module not installed",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Wed Jun 8 17:13:04 UTC 2022)",
    "uid": "b3ac0c6766d04a03",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/gloria_highend/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 12.057480383072207,
    "Location": "closed/Qualcomm/results/gloria_highend/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "gloria_highend",
    "Result": 371.142,
    "Result_Power": 30.78105775075988,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Foxconn Gloria (Highend)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 20W Accelerator TDP constraints; optional SSD and 5G module not installed",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Wed Jun 8 17:13:04 UTC 2022)",
    "uid": "b3ac0c6766d04a03",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/gloria_highend/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 8.1149330793841,
    "Location": "closed/Qualcomm/results/r282_z93_q5e/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q5e",
    "Result": 3335.45,
    "Result_Power": 411.0261868300152,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE R282-Z93 (5x QAIC100 Pro, EE)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-148-generic #165-Ubuntu SMP Tue Apr 18 08:53:12 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "94ad969ee14f4b6d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/r282_z93_q5e/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 8.1149330793841,
    "Location": "closed/Qualcomm/results/r282_z93_q5e/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q5e",
    "Result": 3335.45,
    "Result_Power": 411.0261868300152,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE R282-Z93 (5x QAIC100 Pro, EE)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-148-generic #165-Ubuntu SMP Tue Apr 18 08:53:12 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "94ad969ee14f4b6d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/r282_z93_q5e/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.23201936457062,
    "Accuracy_div_100": 0.90232,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 2.7212971060141684,
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": 926.518,
    "Result_Power": 340.4692556179774,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2,",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "b300ff2bb0e74466",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.23201936457062,
    "Accuracy_div_100": 0.90232,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 2.7212971060141684,
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": 926.518,
    "Result_Power": 340.4692556179774,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2,",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "b300ff2bb0e74466",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 7.447271500915392,
    "Location": "closed/HPE/results/e920d_q4_std/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "e920d_q4_std",
    "Result": 2996.42,
    "Result_Power": 402.35138461538446,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant e920d (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8351N CPU @ 2.40 GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints; Edgeline EL8000 chassis. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "47bcdfe8d9844335",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/e920d_q4_std/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 7.447271500915392,
    "Location": "closed/HPE/results/e920d_q4_std/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "e920d_q4_std",
    "Result": 2996.42,
    "Result_Power": 402.35138461538446,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant e920d (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8351N CPU @ 2.40 GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints; Edgeline EL8000 chassis. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "47bcdfe8d9844335",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/e920d_q4_std/bert-99/offline",
    "version": "v3.1"
  }
]
