[
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_NX_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT_MaxQ",
    "Result": 327.791,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin NX 16G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario; WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "136300db19d04b44",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT_MaxQ/rnnt/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_NX_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT_MaxQ",
    "Result": null,
    "Result_Power": 17.25470198675497,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin NX 16G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario; WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "c2b6825023fc436e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT_MaxQ/rnnt/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.54549144287357,
    "Accuracy_div_100": 0.92545,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "orin-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 982.043,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (non MaxN image)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "b86d9aabbdad4365",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.54549144287357,
    "Accuracy_div_100": 0.92545,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "orin-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": null,
    "Result_Power": 27.567329286798177,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (non MaxN image)",
    "SystemType": "edge",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "fa45f10a51b54464",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 15377.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "76351517604542ef",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": null,
    "Result_Power": 615.3015337423307,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "a0cf2f37adf14e4b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 1653.04,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (64K page size)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "5171bfa319f547b2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": null,
    "Result_Power": 59.27569640062601,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (64K page size)",
    "SystemType": "edge",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "f55768fecd0e461d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 1565.78,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (4K page size)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Jetson Linux 35.3.1, Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "a11f9dc3bd754de2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": null,
    "Result_Power": 57.192151898734195,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (4K page size)",
    "SystemType": "edge",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Jetson Linux 35.3.1, Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "dcd027c237a041e6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.54323660059978,
    "Accuracy_div_100": 0.92543,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": 3927.26,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2,",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "a1e7a51c92194511",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/rnnt/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.54323660059978,
    "Accuracy_div_100": 0.92543,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/rnnt/Offline",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": null,
    "Result_Power": 340.507682926829,
    "Result_Units": "Watts",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2,",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "0a56418d03b74a78",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/rnnt/Offline",
    "version": "v3.1"
  }
]
