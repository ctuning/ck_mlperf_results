[
  {
    "Accuracy": 90.24039214279352,
    "Accuracy_div_100": 0.9024,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/IEI/results/NF5468M6_A40x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "IEI",
    "Platform": "NF5468M6_A40x1_TRT",
    "Result": 1786.63,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5468M6 (1x A40, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "38989d2bfae84e98",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/IEI/results/NF5468M6_A40x1_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.8791726326272,
    "Accuracy_div_100": 0.90879,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/7920t-kilt-onnxruntime_gpu/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "7920t-kilt-onnxruntime_gpu",
    "Result": 63.7166,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux chai 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "05cc4ef8218e4dda",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Krai/results/7920t-kilt-onnxruntime_gpu/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/7920t-kilt-onnxruntime_cpu/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "7920t-kilt-onnxruntime_cpu",
    "Result": 3.95928,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell Precision 7920 Tower",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime CPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux chai 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "e0f85695c2d34c37",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Krai/results/7920t-kilt-onnxruntime_cpu/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28067760460972,
    "Accuracy_div_100": 0.90281,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/TTA/results/KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "TTA",
    "Platform": "KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 742.601,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "KR580S1",
    "SystemType": "edge,datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "tensorrt 8.6.1, ",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6140 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-4.18.0-448.el8.x86_64-glibc2.35)",
    "uid": "6a69d1ae7ecb4ac5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/TTA/results/KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/TTA/results/KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "TTA",
    "Platform": "KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 359.255,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "KR580S1",
    "SystemType": "edge,datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "tensorrt 8.6.1, ",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6140 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-4.18.0-448.el8.x86_64-glibc2.35)",
    "uid": "33e9527d5acd4aa4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/TTA/results/KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99.9/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.541,
    "Accuracy_div_100": 0.90541,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ConnectTechInc/results/Orin_NX_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ConnectTechInc",
    "Platform": "Orin_NX_TRT",
    "Result": 164.354,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin NX 16G (TensorRT) + CTI Hadron Carrier (NGX012)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "CTI Hadron Carrier for Orin-NX/Orin-NANO (NGX012) is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "CTI Jetson BSP ORIN-NX-NANO-35.3.1-V002-MLPERF (Jetson r35.3.1 L4T)",
    "uid": "e13229e0f90346e2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ConnectTechInc/results/Orin_NX_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.552,
    "Accuracy_div_100": 0.90552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT",
    "Result": 553.693,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "945f0af5691642a9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.552,
    "Accuracy_div_100": 0.90552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_NX_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT",
    "Result": 194.503,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA Orin NX 16G (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "401b307650b247b9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/macbook_pro_m1_2-reference-cpu-pytorch-v2.0.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-pytorch-v2.0.0-default_config",
    "Result": 2.33492,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Pytorch v2.0.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "macOS Ventura 13.4.1 (darwin-22.5.0)",
    "uid": "d032261269854549",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/macbook_pro_m1_2-reference-cpu-pytorch-v2.0.0-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87410716832628,
    "Accuracy_div_100": 0.90874,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/macbook_pro_m1_2-reference-cpu-tf-v2.13.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-tf-v2.13.0-default_config",
    "Result": 9.48652,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Tensorflow v2.13.0 with tensorflow-metal",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "macOS Ventura 13.4.1 (darwin-22.5.0)",
    "uid": "e333a71fb4c540ed",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/macbook_pro_m1_2-reference-cpu-tf-v2.13.0-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.25227185929225,
    "Accuracy_div_100": 0.90252,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/aws_t4-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "aws_t4-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 326.109,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-1028-aws-glibc2.35)",
    "uid": "475bc7b54c2d4aa9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/aws_t4-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28067760460972,
    "Accuracy_div_100": 0.90281,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/aws_g4dn.xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "aws_g4dn.xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 435.814,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "edge,datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-1029-aws-glibc2.35)",
    "uid": "2b3034fe6eff45dd",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/aws_g4dn.xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.33322530357985,
    "Accuracy_div_100": 0.90333,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/rigel-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "rigel-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 14649.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "One Stop Systems Rigel Edge Supercomputer",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA HGX A100 SXM",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7502 32-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-78-generic-glibc2.35)",
    "uid": "b674a2236f46444d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/rigel-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35921728409352,
    "Accuracy_div_100": 0.90359,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/amd_ryzen_workstation_triton-nvidia_original-gpu-tensorrt-vdefault-using_triton/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation_triton-nvidia_original-gpu-tensorrt-vdefault-using_triton",
    "Result": 4117.21,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 PC (Nvidia Triton server)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.19.0-46-generic-glibc2.31)",
    "uid": "fd7f26993e134f10",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation_triton-nvidia_original-gpu-tensorrt-vdefault-using_triton/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/macbook_pro_m1_2-reference-cpu-onnxruntime-v1.15.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "macbook_pro_m1_2-reference-cpu-onnxruntime-v1.15.1-default_config",
    "Result": 1.69019,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Apple MacBook Pro M1",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 10,
    "host_processor_model_name": "Apple M1 Pro",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "macOS Ventura 13.4.1 (darwin-22.5.0)",
    "uid": "fd18727ccae5424f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/macbook_pro_m1_2-reference-cpu-onnxruntime-v1.15.1-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.2147015680108,
    "Accuracy_div_100": 0.90215,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_L40_PCIe_48GBx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_L40_PCIe_48GBx2_TRT",
    "Result": 3924.65,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo ThinkEdge SE450 Edge Server (2x NVIDIA L40 PCIe 48GB)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40-PCIE-48GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "be9b112a00a14fee",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/Lenovo_L40_PCIe_48GBx2_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q5/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q5",
    "Result": 4084.79,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE R282-Z93 (5x QAIC100 Pro)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-148-generic #165-Ubuntu SMP Tue Apr 18 08:53:12 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "99fed9f60fa64bba",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/r282_z93_q5/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx1_TRT",
    "Result": 51.7954,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x NVIDIA H100 80GB HBM3, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 80GB HBM3",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "987bdda724b34ab5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx1_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR7620_L4x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR7620_L4x1_TRT",
    "Result": 970.388,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR7620 (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "2576c6f8ec0f45e5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR7620_L4x1_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_L4x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR4520c_L4x1_TRT",
    "Result": 952.511,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR4520c (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "414d8af7e82a4e5a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR4520c_L4x1_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/xr4520c_q2_std/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "xr4520c_q2_std",
    "Result": 1504.21,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR4520c (2x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Dell XR4000r chassis. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "cc8eb9d312494a68",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/xr4520c_q2_std/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.23848090934187,
    "Accuracy_div_100": 0.90238,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40x4_edge_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_L40x4_edge_TRT",
    "Result": 8311.43,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "7886ab4ab1fd4f49",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_L40x4_edge_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.38717702764424,
    "Accuracy_div_100": 0.90387,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nutanix",
    "Platform": "NX_3155G_G8_A100_PCIe_80GBx2_TRT",
    "Result": 6241.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NX_3155G_G8_A100_PCIe_80GBx2",
    "SystemType": "edge,datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354 CPU @ 3.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "d7fffca20c48453f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.88084722099202,
    "Accuracy_div_100": 0.90881,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nutanix",
    "Platform": "NX_3155G_G8_A100_PCIe_80GBx2_TRT",
    "Result": 3275.44,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NX_3155G_G8_A100_PCIe_80GBx2",
    "SystemType": "edge,datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354 CPU @ 3.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "fc58a73c76c54a02",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.23848090934187,
    "Accuracy_div_100": 0.90238,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_L40x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5300G6_L40x1_TRT",
    "Result": 2252.62,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G6 (1x L40, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "54fd9305831c40ba",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/H3C/results/R5300G6_L40x1_TRT/bert-99/Offline",
    "version": "v3.1"
  }
]
