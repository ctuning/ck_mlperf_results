[
  {
    "Accuracy": 37.527,
    "Accuracy_div_100": 0.37527,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/IEI/results/NF5468M6_A40x1_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "IEI",
    "Platform": "NF5468M6_A40x1_TRT",
    "Result": 4.113398,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NF5468M6 (1x A40, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "938c10b743614633",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/IEI/results/NF5468M6_A40x1_TRT/retinanet/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.333,
    "Accuracy_div_100": 0.37333,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/TTA/results/KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/singlestream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "TTA",
    "Platform": "KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 11.685866,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "KR580S1",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "tensorrt 8.6.1, ",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6140 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-4.18.0-448.el8.x86_64-glibc2.35)",
    "uid": "aaaf8376b3464d06",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/TTA/results/KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.339,
    "Accuracy_div_100": 0.37339,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ConnectTechInc/results/Orin_NX_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ConnectTechInc",
    "Platform": "Orin_NX_TRT",
    "Result": 28.581945,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Orin NX 16G (TensorRT) + CTI Hadron Carrier (NGX012)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "CTI Hadron Carrier for Orin-NX/Orin-NANO (NGX012) is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "CTI Jetson BSP ORIN-NX-NANO-35.3.1-V002-MLPERF (Jetson r35.3.1 L4T)",
    "uid": "b84f0c45d27b4505",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ConnectTechInc/results/Orin_NX_TRT/retinanet/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.373,
    "Accuracy_div_100": 0.37373,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT",
    "Result": 11.674034,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "a4e833efd45e4d4a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_TRT/retinanet/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.374,
    "Accuracy_div_100": 0.37374,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_NX_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT",
    "Result": 28.629758,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Orin NX 16G (TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "0e16cce85e014b66",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT/retinanet/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.347,
    "Accuracy_div_100": 0.37347,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/aws_t4-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/singlestream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "aws_t4-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 13.214438,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-1028-aws-glibc2.35)",
    "uid": "7c5f8f001ce045e2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/aws_t4-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/amd_ryzen_workstation-reference-cpu-pytorch-v2.0.1-default_config/retinanet/singlestream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-reference-cpu-pytorch-v2.0.1-default_config",
    "Result": 437.916361,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons reference implementation with CM API, Pytorch v2.0.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "1b84226e87c04de6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-reference-cpu-pytorch-v2.0.1-default_config/retinanet/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.347,
    "Accuracy_div_100": 0.37347,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/aws_g4dn.xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/singlestream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "aws_g4dn.xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 13.214438,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-1029-aws-glibc2.35)",
    "uid": "3ae959eb3434420e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/aws_g4dn.xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.411,
    "Accuracy_div_100": 0.37411,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/rigel-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/singlestream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "rigel-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 3.207242,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "One Stop Systems Rigel Edge Supercomputer",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA HGX A100 SXM",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7502 32-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-78-generic-glibc2.35)",
    "uid": "9bb5cd620813487a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/rigel-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.572,
    "Accuracy_div_100": 0.37572,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/amd_ryzen_workstation-cpp-cpu-onnxruntime-vdefault-default_config/retinanet/singlestream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-cpp-cpu-onnxruntime-vdefault-default_config",
    "Result": 454.104916,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "cTuning/MLCommons C++ Modular Inference Library (MIL), Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-50-generic-glibc2.35)",
    "uid": "0b5943ba2de74661",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-cpp-cpu-onnxruntime-vdefault-default_config/retinanet/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.393,
    "Accuracy_div_100": 0.37393,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/amd_ryzen_workstation_triton-nvidia_original-gpu-tensorrt-vdefault-using_triton/retinanet/singlestream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation_triton-nvidia_original-gpu-tensorrt-vdefault-using_triton",
    "Result": 2.083004,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC (Nvidia Triton server)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.19.0-46-generic-glibc2.31)",
    "uid": "03cd5217660c4517",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation_triton-nvidia_original-gpu-tensorrt-vdefault-using_triton/retinanet/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.573,
    "Accuracy_div_100": 0.37573,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/amd_ryzen_workstation-cpp-gpu-onnxruntime-vdefault-default_config/retinanet/singlestream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "amd_ryzen_workstation-cpp-gpu-onnxruntime-vdefault-default_config",
    "Result": 18.321944,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "cTuning/MLCommons C++ Modular Inference Library (MIL), Onnxruntime v1.15.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "b6a7deed30354723",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_ryzen_workstation-cpp-gpu-onnxruntime-vdefault-default_config/retinanet/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.329,
    "Accuracy_div_100": 0.37329,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_L40_PCIe_48GBx2_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "Lenovo_L40_PCIe_48GBx2_TRT",
    "Result": 2.365422,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Lenovo ThinkEdge SE450 Edge Server (2x NVIDIA L40 PCIe 48GB)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40-PCIE-48GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e3b766004069423a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/Lenovo_L40_PCIe_48GBx2_TRT/retinanet/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q5/retinanet/singlestream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q5",
    "Result": 12.573332,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "GIGABYTE R282-Z93 (5x QAIC100 Pro)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-148-generic #165-Ubuntu SMP Tue Apr 18 08:53:12 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "802c7010d5c24805",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/r282_z93_q5/retinanet/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.399,
    "Accuracy_div_100": 0.37399,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR7620_L4x1_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XR7620_L4x1_TRT",
    "Result": 4.719174,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XR7620 (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "293fb8e6d7904169",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR7620_L4x1_TRT/retinanet/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.421,
    "Accuracy_div_100": 0.37421,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_L4x1_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XR4520c_L4x1_TRT",
    "Result": 4.752571,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XR4520c (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "0be65c532f9a4d47",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR4520c_L4x1_TRT/retinanet/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/xr4520c_q2_std/retinanet/singlestream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "xr4520c_q2_std",
    "Result": 11.519952,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XR4520c (2x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Dell XR4000r chassis. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "2d9718e84fb64b35",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/xr4520c_q2_std/retinanet/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.379,
    "Accuracy_div_100": 0.37379,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40x4_edge_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_L40x4_edge_TRT",
    "Result": 1.82124,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge R760xa (4x L40, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "edc22d4fa9ac4b65",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_L40x4_edge_TRT/retinanet/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.485,
    "Accuracy_div_100": 0.37485,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nutanix",
    "Platform": "NX_3155G_G8_A100_PCIe_80GBx2_TRT",
    "Result": 2.854521,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NX_3155G_G8_A100_PCIe_80GBx2",
    "SystemType": "edge,datacenter",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354 CPU @ 3.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "4a3e65f3963b4bb1",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/retinanet/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.352,
    "Accuracy_div_100": 0.37352,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_L40x1_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5300G6_L40x1_TRT",
    "Result": 1.827584,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "H3C UniServer R5300 G6 (1x L40, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "633ba4ee87924cdf",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/H3C/results/R5300G6_L40x1_TRT/retinanet/SingleStream",
    "version": "v3.1"
  }
]
